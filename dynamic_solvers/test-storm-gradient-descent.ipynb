{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdbf7063",
   "metadata": {},
   "source": [
    "# Environment for specific POMDP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T13:44:49.555968Z",
     "start_time": "2025-12-28T13:44:48.817777Z"
    }
   },
   "outputs": [],
   "source": [
    "from StormExecutor import StormExecutor, _build_sensor_selection_const, _build_world_definition_const, \\\n",
    "    _define_program_constants, _configure_buildfull_options\n",
    "from builders.POMDPAdapter import POMDPAdapter\n",
    "from builders.ssp import LineTPMC\n",
    "import stormpy\n",
    "import stormpy.pomdp\n",
    "import stormpy.pars\n",
    "\n",
    "tpmc = LineTPMC(budget=30, goal=30, length=61)\n",
    "pomdp = POMDPAdapter(tpmc)\n",
    "exec = StormExecutor(verbose=True, puzzle_type=pomdp.puzzle_type)\n",
    "\n",
    "\n",
    "obs_function = [1] + [1]*29 + [-1] + [0]*30\n",
    "constants = {\n",
    "    **_build_sensor_selection_const(obs_function, 50),\n",
    "    **_build_world_definition_const(pomdp),\n",
    "}\n",
    "\n",
    "# Instantiate all constant parameters in the PRISM model\n",
    "static_program = _define_program_constants(exec.static_program, constants)\n",
    "\n",
    "# Build the parsed POMDP model with full labels and rewards (make it canonic)\n",
    "build_options = _configure_buildfull_options()\n",
    "model = stormpy.build_sparse_exact_model_with_options(static_program, build_options)\n",
    "model = stormpy.build_sparse_model_with_options(static_program, build_options)\n",
    "model = stormpy.pomdp.make_canonic(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7590eae9",
   "metadata": {},
   "source": [
    "### Parameter Synthesis using Region Verification (weak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a93833abc3545b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T13:44:51.010465Z",
     "start_time": "2025-12-28T13:44:51.002888Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert POMDP to parametric model using unknown FSC\n",
    "parametric_model = stormpy.pomdp.apply_unknown_fsc(\n",
    "    model,\n",
    "    stormpy.pomdp.PomdpFscApplicationMode.simple_linear\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187155f9c95e48db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Parameter synthesis (requires bounded reward property <= tau)\n",
    "env = stormpy.Environment()\n",
    "checker = stormpy.pars.create_region_checker(env, parametric_model, exec.property[0].raw_formula)\n",
    "parameters = parametric_model.collect_probability_parameters()\n",
    "print(parameters)\n",
    "\n",
    "valuations = { parameter: (0, 1) for parameter in parameters }\n",
    "region = stormpy.pars.ParameterRegion(valuations)\n",
    "synthesis_result = checker.check_region(env, region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded50c5bf27b3824",
   "metadata": {},
   "source": [
    "# Parametric MC with Gradient Descent for Memory-less POMDP Controllers\n",
    "\n",
    "To integrate a parametric Markov chain in a Gradient Descent algorithm for computing memory-less POMDP controllers, one needs to combine `stormpy`'s parametric analysis capabilities with optimization logic.\n",
    "\n",
    "## Core Approach\n",
    "The key is to use the parametric model from `apply_unknown_fsc` as a differentiable function that maps controller parameters to verification results, then apply gradient descent to optimize these parameters. Using the `simple_linear` FSC application mode, we enforce a POMDP to pMC conversion that assumes no memory states (i.e. memory-less controllers).\n",
    "\n",
    "Implementation Steps\n",
    "1. Create Parametric Model with Unknown FSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "996ee37bcdf5d69f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T13:30:25.787799Z",
     "start_time": "2025-12-28T13:30:25.779121Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert POMDP to parametric model using unknown FSC\n",
    "parametric_model = stormpy.pomdp.apply_unknown_fsc(\n",
    "    model,\n",
    "    stormpy.pomdp.PomdpFscApplicationMode.simple_linear\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138386773068ce62",
   "metadata": {},
   "source": [
    "2. Extract Parameters and Derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "800bb51f8ba0a5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T13:45:02.250109Z",
     "start_time": "2025-12-28T13:45:02.242734Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{<Variable p14_0 [id = 3]>, <Variable p32_0 [id = 4]>, <Variable p22_0 [id = 5]>, <Variable p20_0 [id = 6]>, <Variable p27_0 [id = 7]>, <Variable p28_0 [id = 8]>, <Variable p18_0 [id = 9]>, <Variable p2_0 [id = 10]>, <Variable p29_0 [id = 11]>, <Variable p5_0 [id = 12]>, <Variable p12_0 [id = 13]>, <Variable p8_0 [id = 14]>, <Variable p4_0 [id = 15]>, <Variable p19_0 [id = 16]>, <Variable p21_0 [id = 17]>, <Variable p10_0 [id = 18]>, <Variable p23_0 [id = 19]>, <Variable p6_0 [id = 20]>, <Variable p25_0 [id = 21]>, <Variable p24_0 [id = 22]>, <Variable p11_0 [id = 23]>, <Variable p3_0 [id = 24]>, <Variable p26_0 [id = 25]>, <Variable p7_0 [id = 26]>, <Variable p17_0 [id = 27]>, <Variable p13_0 [id = 28]>, <Variable p30_0 [id = 29]>, <Variable p9_0 [id = 30]>, <Variable p16_0 [id = 31]>, <Variable p31_0 [id = 32]>, <Variable p0_0 [id = 33]>, <Variable p1_0 [id = 34]>, <Variable p1_1 [id = 35]>}\n",
      "-------------------------------------------------------------- \n",
      "Model type: \tDTMC (sparse)\n",
      "States: \t62\n",
      "Transitions: \t183\n",
      "Reward Models:  (default)\n",
      "State Labels: \t3 labels\n",
      "   * deadlock -> 0 item(s)\n",
      "   * gameover -> 1 item(s)\n",
      "   * init -> 1 item(s)\n",
      "Choice Labels: \tnone\n",
      "-------------------------------------------------------------- \n",
      "\n",
      "{<Variable p14_0 [id = 3]>: set(), <Variable p32_0 [id = 4]>: set(), <Variable p22_0 [id = 5]>: set(), <Variable p20_0 [id = 6]>: set(), <Variable p27_0 [id = 7]>: set(), <Variable p28_0 [id = 8]>: set(), <Variable p18_0 [id = 9]>: set(), <Variable p2_0 [id = 10]>: set(), <Variable p29_0 [id = 11]>: set(), <Variable p5_0 [id = 12]>: set(), <Variable p12_0 [id = 13]>: set(), <Variable p8_0 [id = 14]>: set(), <Variable p4_0 [id = 15]>: set(), <Variable p19_0 [id = 16]>: set(), <Variable p21_0 [id = 17]>: set(), <Variable p10_0 [id = 18]>: set(), <Variable p23_0 [id = 19]>: set(), <Variable p6_0 [id = 20]>: set(), <Variable p25_0 [id = 21]>: set(), <Variable p24_0 [id = 22]>: set(), <Variable p11_0 [id = 23]>: set(), <Variable p3_0 [id = 24]>: set(), <Variable p26_0 [id = 25]>: set(), <Variable p7_0 [id = 26]>: set(), <Variable p17_0 [id = 27]>: set(), <Variable p13_0 [id = 28]>: set(), <Variable p30_0 [id = 29]>: set(), <Variable p9_0 [id = 30]>: set(), <Variable p16_0 [id = 31]>: set(), <Variable p31_0 [id = 32]>: set(), <Variable p0_0 [id = 33]>: set(), <Variable p1_0 [id = 34]>: {<stormpy.pycarl.cln.FactorizedPolynomial object at 0x10c5c6470>, <stormpy.pycarl.cln.FactorizedPolynomial object at 0x10c5c6ef0>}, <Variable p1_1 [id = 35]>: {<stormpy.pycarl.cln.FactorizedPolynomial object at 0x10c5c5fb0>, <stormpy.pycarl.cln.FactorizedPolynomial object at 0x10c5c6ab0>}}\n"
     ]
    }
   ],
   "source": [
    "# Collect model parameters\n",
    "parameters = parametric_model.collect_probability_parameters()\n",
    "\n",
    "print(parameters)\n",
    "print(parametric_model)\n",
    "\n",
    "# Function to compute gradients\n",
    "def compute_gradients(parametric_model, parameters):\n",
    "    gradients = {}\n",
    "    for param in parameters:\n",
    "        # Gather derivatives for each parameter\n",
    "        derivatives = stormpy.pars.gather_derivatives(parametric_model, param)\n",
    "        gradients[param] = derivatives\n",
    "    return gradients\n",
    "\n",
    "print(compute_gradients(parametric_model, parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71ba0675ff358843",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T13:45:09.097709Z",
     "start_time": "2025-12-28T13:45:09.088181Z"
    }
   },
   "outputs": [],
   "source": [
    "import stormpy.pycarl.cln\n",
    "\n",
    "# Function to evaluate gradients using current values for parameters\n",
    "def evaluate_gradient(gradient_formulas: set, values: dict):\n",
    "    if len(gradient_formulas) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        gradient_polynomial = gradient_formulas.pop()\n",
    "        grad_val = gradient_polynomial.evaluate(values)\n",
    "        return float(grad_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fb699809055aea",
   "metadata": {},
   "source": [
    "3. Gradient Descent Optimization Loop (Baseline)\n",
    "\n",
    "**Update Rule:**\n",
    "```\n",
    "θ_{t+1} = θ_t - η ∇f(θ_t)\n",
    "```\n",
    "\n",
    "Where:\n",
    "- $\\theta_t$: parameters at iteration $t$\n",
    "- $\\eta$: learning rate (step size)\n",
    "- $\\nabla f(\\theta_t)$: gradient of objective function at $\\theta_t$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48967b70a7438b46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T13:45:37.032968Z",
     "start_time": "2025-12-28T13:45:37.013681Z"
    }
   },
   "outputs": [],
   "source": [
    "def gradient_descent_optimization(parametric_model, formula, parameters,\n",
    "                                learning_rate=0.01, max_iterations=100):\n",
    "    # Initialize parameters\n",
    "    current_values = {p: stormpy.RationalRF(0.5) for p in parameters}\n",
    "    instantiator = stormpy.pars.ModelInstantiator(parametric_model)\n",
    "\n",
    "    for iteration in range(max_iterations):\n",
    "        # Instantiate model with current parameters\n",
    "        concrete_model = instantiator.instantiate(current_values)\n",
    "\n",
    "        # Model check to get objective value\n",
    "        result = stormpy.model_checking(concrete_model, formula)\n",
    "        objective = float(result.at(concrete_model.initial_states[0]))\n",
    "\n",
    "        # Compute gradients (symbolic differentiation)\n",
    "        gradients = compute_gradients(parametric_model, parameters)\n",
    "\n",
    "        # Update parameters using gradient descent\n",
    "        for param in parameters:\n",
    "            # print(f\"Parameter: {param}, Gradient: {gradients[param]}, Value: {float(current_values[param])}\")\n",
    "            # Convert symbolic gradient to numeric\n",
    "            grad_value = evaluate_gradient(gradients[param], current_values)\n",
    "            current_values[param] = stormpy.RationalRF(\n",
    "                float(current_values[param]) - learning_rate * grad_value\n",
    "            )\n",
    "\n",
    "        print(f\"Iteration {iteration}: Objective = {objective}\")\n",
    "\n",
    "    return current_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0ab5482ecf8bf9",
   "metadata": {},
   "source": [
    "\n",
    "4. Run Gradient Descent - extract memory-less controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "621ad6c9bae9d69c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T01:17:01.049864Z",
     "start_time": "2025-12-28T01:17:01.044365Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check CLN availability\n",
    "from stormpy import pycarl\n",
    "if not pycarl.has_cln():\n",
    "    raise ImportError(\"CLN backend not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5555fbb54841b97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T13:45:47.369552Z",
     "start_time": "2025-12-28T13:45:47.248064Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Objective = 630.3333333333331\n",
      "Iteration 1: Objective = 630.3333333333331\n",
      "Iteration 2: Objective = 630.3333333333331\n",
      "Iteration 3: Objective = 630.3333333333331\n",
      "Iteration 4: Objective = 630.3333333333331\n",
      "Iteration 5: Objective = 630.3333333333331\n",
      "Iteration 6: Objective = 630.3333333333331\n",
      "Iteration 7: Objective = 630.3333333333331\n",
      "Iteration 8: Objective = 630.3333333333331\n",
      "Iteration 9: Objective = 630.3333333333331\n",
      "Iteration 10: Objective = 630.3333333333331\n",
      "Iteration 11: Objective = 630.3333333333331\n",
      "Iteration 12: Objective = 630.3333333333331\n",
      "Iteration 13: Objective = 630.3333333333331\n",
      "Iteration 14: Objective = 630.3333333333331\n",
      "Iteration 15: Objective = 630.3333333333331\n",
      "Iteration 16: Objective = 630.3333333333331\n",
      "Iteration 17: Objective = 630.3333333333331\n",
      "Iteration 18: Objective = 630.3333333333331\n",
      "Iteration 19: Objective = 630.3333333333331\n",
      "Iteration 20: Objective = 630.3333333333331\n",
      "Iteration 21: Objective = 630.3333333333331\n",
      "Iteration 22: Objective = 630.3333333333331\n",
      "Iteration 23: Objective = 630.3333333333331\n",
      "Iteration 24: Objective = 630.3333333333331\n",
      "Iteration 25: Objective = 630.3333333333331\n",
      "Iteration 26: Objective = 630.3333333333331\n",
      "Iteration 27: Objective = 630.3333333333331\n",
      "Iteration 28: Objective = 630.3333333333331\n",
      "Iteration 29: Objective = 630.3333333333331\n",
      "Iteration 30: Objective = 630.3333333333331\n",
      "Iteration 31: Objective = 630.3333333333331\n",
      "Iteration 32: Objective = 630.3333333333331\n",
      "Iteration 33: Objective = 630.3333333333331\n",
      "Iteration 34: Objective = 630.3333333333331\n",
      "Iteration 35: Objective = 630.3333333333331\n",
      "Iteration 36: Objective = 630.3333333333331\n",
      "Iteration 37: Objective = 630.3333333333331\n",
      "Iteration 38: Objective = 630.3333333333331\n",
      "Iteration 39: Objective = 630.3333333333331\n",
      "Iteration 40: Objective = 630.3333333333331\n",
      "Iteration 41: Objective = 630.3333333333331\n",
      "Iteration 42: Objective = 630.3333333333331\n",
      "Iteration 43: Objective = 630.3333333333331\n",
      "Iteration 44: Objective = 630.3333333333331\n",
      "Iteration 45: Objective = 630.3333333333331\n",
      "Iteration 46: Objective = 630.3333333333331\n",
      "Iteration 47: Objective = 630.3333333333331\n",
      "Iteration 48: Objective = 630.3333333333331\n",
      "Iteration 49: Objective = 630.3333333333331\n"
     ]
    }
   ],
   "source": [
    "# Run gradient descent\n",
    "optimal_parameters = gradient_descent_optimization(\n",
    "    parametric_model, exec.property[0].raw_formula, parameters,\n",
    "    learning_rate=0.05, max_iterations=50\n",
    ")\n",
    "\n",
    "# Get final controller\n",
    "instantiator = stormpy.pars.ModelInstantiator(parametric_model)\n",
    "optimal_model = instantiator.instantiate(optimal_parameters)\n",
    "final_result = stormpy.model_checking(optimal_model, exec.property[0].raw_formula)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f0ad26bbb9b4e0",
   "metadata": {},
   "source": [
    "\n",
    "### Theoretical Foundations of Standard Gradient Descent (Baseline)\n",
    "\n",
    "**Update Rule:**\n",
    "```\n",
    "θ_{t+1} = θ_t - η ∇f(θ_t)\n",
    "```\n",
    "\n",
    "Where:\n",
    "- $\\theta_t$: parameters at iteration $t$\n",
    "- $\\eta$: learning rate (step size)\n",
    "- $\\nabla f(\\theta_t)$: gradient of objective function at $\\theta_t$\n",
    "\n",
    "**Limitations:**\n",
    "- **Slow convergence** in ravines (regions where surface curves more steeply in one dimension than another)\n",
    "- **Oscillation** across narrow valleys\n",
    "- **Fixed learning rate** may be too large (divergence) or too small (slow convergence)\n",
    "- **Saddle points**: can get stuck where gradient is zero but not at optimum\n",
    "\n",
    "---\n",
    "\n",
    "### Key Components\n",
    "\n",
    ">   `apply_unknown_fsc`: Creates parametric model with FSC parameters from POMDP\n",
    "\n",
    ">   ModelInstantiator: Instantiates parametric models with specific values\n",
    "\n",
    ">   `gather_derivatives`: Computes symbolic derivatives of transition probabilities\n",
    "\n",
    ">   Parametric model checking: Returns symbolic results for gradient computation\n",
    "\n",
    "### Memory-less Strategy Enforcement\n",
    "\n",
    "The `SIMPLE_LINEAR` FSC application mode ensures memory-less strategies by:\n",
    "\n",
    "- Using a linear parameterization without memory states\n",
    "- Mapping observations directly to action probabilities\n",
    "- Enforcing that the controller depends only on current observations\n",
    "\n",
    "### Notes\n",
    "\n",
    "- Stormpy provides the parametric model and derivative computation, but the gradient descent algorithm must be implemented in Python\n",
    "- The `gather_derivatives` function returns symbolic derivatives that need to be evaluated numerically (**issue: not always computed for each parameter**)\n",
    "- Learning rate and convergence criteria should be tuned based on the specific POMDP\n",
    "- The approach works for reachability and probability properties; reward properties may need different handling\n",
    "\n",
    "### Conclusion\n",
    "At each step the derivatives extracted from stormpy are zero for most parameters, hence they seem to not affect the reward objective, which is in fact unrealistic. The problem might be too complex for symbolic derivatives and potentially not be captured by gradient-based methods. Alternatives: random search or evolutionary algorithms or policy gradient (REINFORCE with trajectory sampling)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fqrwh5g0xrs",
   "metadata": {},
   "source": [
    "# Advanced Gradient Descent Optimizers\n",
    "\n",
    "Below are enhanced optimization algorithms with momentum and adaptive learning rates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tesrmb54u9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Improved gradient evaluation that handles multiple derivatives\n",
    "def evaluate_gradient_improved(gradient_formulas: set, values: dict):\n",
    "    \"\"\"\n",
    "    Evaluate all gradient polynomials and aggregate them (sum or average).\n",
    "    This handles cases where multiple derivatives exist for a parameter.\n",
    "    \"\"\"\n",
    "    if len(gradient_formulas) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # Make a copy to avoid modifying the original set\n",
    "    formulas = gradient_formulas.copy()\n",
    "    total_grad = 0.0\n",
    "    count = 0\n",
    "    \n",
    "    for gradient_polynomial in formulas:\n",
    "        try:\n",
    "            grad_val = gradient_polynomial.evaluate(values)\n",
    "            total_grad += float(grad_val)\n",
    "            count += 1\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return total_grad / count if count > 0 else 0.0\n",
    "\n",
    "# Helper function to clip parameter values to valid probability range\n",
    "def clip_probability(value, epsilon=1e-6):\n",
    "    \"\"\"Clip value to [epsilon, 1-epsilon] to maintain valid probabilities.\"\"\"\n",
    "    return max(epsilon, min(1.0 - epsilon, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5g69778sor",
   "metadata": {},
   "source": [
    "### Momentum-based Gradient Descent\n",
    "\n",
    "**Theoretical Foundation:**\n",
    "\n",
    "Momentum introduces a \"velocity\" term that accumulates gradients over time, inspired by physics where a ball rolling down a hill accumulates momentum.\n",
    "\n",
    "**Update Rules:**\n",
    "```\n",
    "v_t = β v_{t-1} + η ∇f(θ_t)\n",
    "θ_{t+1} = θ_t - v_t\n",
    "```\n",
    "\n",
    "Where:\n",
    "- $v_t$: velocity (exponentially weighted moving average of gradients)\n",
    "- $\\beta$: momentum coefficient (typically 0.9, meaning 90% of previous velocity is retained)\n",
    "\n",
    "**Mathematical Intuition:**\n",
    "\n",
    "The velocity at time $t$ is:\n",
    "```\n",
    "v_t = η(∇f(θ_t) + β∇f(θ_{t-1}) + β²∇f(θ_{t-2}) + β³∇f(θ_{t-3}) + ...)\n",
    "```\n",
    "\n",
    "This creates an exponentially decaying sum of past gradients.\n",
    "\n",
    "**Key Properties:**\n",
    "\n",
    "1. **Acceleration in consistent directions**: If gradients point in the same direction across iterations, velocity builds up\n",
    "2. **Dampening oscillations**: Opposing gradients cancel out, reducing oscillation\n",
    "3. **Escaping local minima**: Accumulated momentum can carry optimization through small local minima\n",
    "4. **Convergence rate (speedup)**: Can achieve $O(1/t^2)$ convergence vs $O(1/t)$ for standard GD in some settings\n",
    "\n",
    "**Why it works:**\n",
    "- In ravines, gradients oscillate perpendicular to the optimum direction but point consistently toward optimum\n",
    "- Momentum accumulates along the ravine while oscillations cancel out\n",
    "- Effectively increases step size in low-curvature directions and decreases in high-curvature directions\n",
    "\n",
    "---\n",
    "\n",
    "Classic gradient descent with momentum accelerates convergence by accumulating past gradients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "l1815o3sk",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_momentum(parametric_model, formula, parameters,\n",
    "                             learning_rate=0.01, momentum=0.9, \n",
    "                             max_iterations=100, convergence_threshold=1e-6,\n",
    "                             minimize=True):\n",
    "    \"\"\"\n",
    "    Gradient Descent with Momentum\n",
    "    \n",
    "    Args:\n",
    "        parametric_model: Storm parametric model\n",
    "        formula: Property formula to optimize\n",
    "        parameters: Model parameters to optimize\n",
    "        learning_rate: Step size for updates\n",
    "        momentum: Momentum coefficient (typically 0.9)\n",
    "        max_iterations: Maximum optimization iterations\n",
    "        convergence_threshold: Stop if objective change < threshold\n",
    "        minimize: True to minimize, False to maximize objective\n",
    "    \"\"\"\n",
    "    # Initialize parameters\n",
    "    current_values = {p: stormpy.RationalRF(0.5) for p in parameters}\n",
    "    instantiator = stormpy.pars.ModelInstantiator(parametric_model)\n",
    "    \n",
    "    # Initialize momentum terms (velocity)\n",
    "    velocity = {p: 0.0 for p in parameters}\n",
    "    \n",
    "    prev_objective = None\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        # Instantiate model with current parameters\n",
    "        concrete_model = instantiator.instantiate(current_values)\n",
    "        \n",
    "        # Model check to get objective value\n",
    "        result = stormpy.model_checking(concrete_model, formula)\n",
    "        objective = float(result.at(concrete_model.initial_states[0]))\n",
    "        \n",
    "        # Check convergence\n",
    "        if prev_objective is not None and abs(objective - prev_objective) < convergence_threshold:\n",
    "            print(f\"Converged at iteration {iteration}\")\n",
    "            break\n",
    "        \n",
    "        # Compute gradients\n",
    "        gradients = compute_gradients(parametric_model, parameters)\n",
    "        \n",
    "        # Update parameters using momentum\n",
    "        for param in parameters:\n",
    "            grad_value = evaluate_gradient_improved(gradients[param], current_values)\n",
    "            \n",
    "            # Apply gradient direction based on minimize/maximize\n",
    "            grad_direction = grad_value if minimize else -grad_value\n",
    "            \n",
    "            # Update velocity with momentum\n",
    "            velocity[param] = momentum * velocity[param] + learning_rate * grad_direction\n",
    "            \n",
    "            # Update parameter value\n",
    "            new_value = float(current_values[param]) - velocity[param]\n",
    "            current_values[param] = stormpy.RationalRF(clip_probability(new_value))\n",
    "        \n",
    "        if iteration % 10 == 0:\n",
    "            print(f\"Iteration {iteration}: Objective = {objective:.6f}\")\n",
    "        \n",
    "        prev_objective = objective\n",
    "    \n",
    "    print(f\"Final Objective: {objective:.6f}\")\n",
    "    return current_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5juvv8o5az9",
   "metadata": {},
   "source": [
    "### RMSprop Optimizer (Root Mean Square Propagation)\n",
    "\n",
    "**Theoretical Foundation:**\n",
    "\n",
    "RMSprop adapts the learning rate for each parameter based on the magnitude of recent gradients. Developed by Geoffrey Hinton to address the problem of radically different gradient scales across parameters.\n",
    "\n",
    "**Update Rules:**\n",
    "```\n",
    "E[g²]_t = ρ E[g²]_{t-1} + (1-ρ) (∇f(θ_t))²\n",
    "θ_{t+1} = θ_t - η / √(E[g²]_t + ε) · ∇f(θ_t)\n",
    "```\n",
    "\n",
    "Where:\n",
    "- $E[g^2]_t$: exponentially weighted moving average of squared gradients\n",
    "- $\\rho$: decay rate (typically 0.9)\n",
    "- $\\epsilon$: small constant for numerical stability (typically $10^{-8}$)\n",
    "\n",
    "**Mathematical Intuition:**\n",
    "\n",
    "For each parameter $\\theta_i$:\n",
    "- If gradients have been consistently large → $E[g^2]_i$ is large → effective learning rate $\\eta/\\sqrt{E[g^2]_i}$ is small\n",
    "- If gradients have been consistently small → $E[g^2]_i$ is small → effective learning rate is large\n",
    "\n",
    "**Key Properties:**\n",
    "\n",
    "1. **Adaptive learning rates**: Each parameter gets its own effective learning rate\n",
    "2. **Normalization**: Dividing by RMS of gradients normalizes the update step\n",
    "3. **Handles different scales**: Parameters with different gradient magnitudes converge at similar rates\n",
    "4. **Non-stationary objectives**: Works well when objective function changes over time\n",
    "\n",
    "**Connection to Second-Order Methods:**\n",
    "\n",
    "RMSprop approximates diagonal preconditioning. The ideal Newton's method update is:\n",
    "```\n",
    "θ_{t+1} = θ_t - H⁻¹ ∇f(θ_t)\n",
    "```\n",
    "\n",
    "Where H is the Hessian (second derivative matrix). RMSprop approximates the diagonal of $H^{-1}$ using gradient statistics.\n",
    "\n",
    "**Why it works:**\n",
    "- Normalizes gradient components by their typical magnitude\n",
    "- Prevents parameters with large gradients from dominating updates\n",
    "- Effectively rescales the parameter space to be more spherical\n",
    "\n",
    "---\n",
    "\n",
    "RMSprop uses adaptive learning rates based on a moving average of squared gradients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mor7gdeq1n9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsprop_optimization(parametric_model, formula, parameters,\n",
    "                        learning_rate=0.001, decay_rate=0.9, epsilon=1e-8,\n",
    "                        max_iterations=100, convergence_threshold=1e-6,\n",
    "                        minimize=True):\n",
    "    \"\"\"\n",
    "    RMSprop Optimizer with adaptive learning rates\n",
    "    \n",
    "    Args:\n",
    "        parametric_model: Storm parametric model\n",
    "        formula: Property formula to optimize\n",
    "        parameters: Model parameters to optimize\n",
    "        learning_rate: Initial learning rate\n",
    "        decay_rate: Decay rate for squared gradient moving average (typically 0.9)\n",
    "        epsilon: Small constant for numerical stability\n",
    "        max_iterations: Maximum optimization iterations\n",
    "        convergence_threshold: Stop if objective change < threshold\n",
    "        minimize: True to minimize, False to maximize objective\n",
    "    \"\"\"\n",
    "    # Initialize parameters\n",
    "    current_values = {p: stormpy.RationalRF(0.5) for p in parameters}\n",
    "    instantiator = stormpy.pars.ModelInstantiator(parametric_model)\n",
    "    \n",
    "    # Initialize squared gradient accumulator\n",
    "    squared_grad = {p: 0.0 for p in parameters}\n",
    "    \n",
    "    prev_objective = None\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        # Instantiate model with current parameters\n",
    "        concrete_model = instantiator.instantiate(current_values)\n",
    "        \n",
    "        # Model check to get objective value\n",
    "        result = stormpy.model_checking(concrete_model, formula)\n",
    "        objective = float(result.at(concrete_model.initial_states[0]))\n",
    "        \n",
    "        # Check convergence\n",
    "        if prev_objective is not None and abs(objective - prev_objective) < convergence_threshold:\n",
    "            print(f\"Converged at iteration {iteration}\")\n",
    "            break\n",
    "        \n",
    "        # Compute gradients\n",
    "        gradients = compute_gradients(parametric_model, parameters)\n",
    "        \n",
    "        # Update parameters using RMSprop\n",
    "        for param in parameters:\n",
    "            grad_value = evaluate_gradient_improved(gradients[param], current_values)\n",
    "            \n",
    "            # Apply gradient direction based on minimize/maximize\n",
    "            grad_direction = grad_value if minimize else -grad_value\n",
    "            \n",
    "            # Update squared gradient moving average\n",
    "            squared_grad[param] = decay_rate * squared_grad[param] + (1 - decay_rate) * grad_direction**2\n",
    "            \n",
    "            # Compute adaptive learning rate\n",
    "            adaptive_lr = learning_rate / (np.sqrt(squared_grad[param]) + epsilon)\n",
    "            \n",
    "            # Update parameter value\n",
    "            new_value = float(current_values[param]) - adaptive_lr * grad_direction\n",
    "            current_values[param] = stormpy.RationalRF(clip_probability(new_value))\n",
    "        \n",
    "        if iteration % 10 == 0:\n",
    "            print(f\"Iteration {iteration}: Objective = {objective:.6f}\")\n",
    "        \n",
    "        prev_objective = objective\n",
    "    \n",
    "    print(f\"Final Objective: {objective:.6f}\")\n",
    "    return current_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zjk6xj9h5oi",
   "metadata": {},
   "source": [
    "### Adam Optimizer (Adaptive Moment Estimation)\n",
    "\n",
    "**Theoretical Foundation:**\n",
    "\n",
    "Adam combines the benefits of momentum (first moment) and RMSprop (second moment) with bias correction. Published by Kingma & Ba (2014), it's one of the most widely used optimizers in deep learning.\n",
    "\n",
    "**Update Rules:**\n",
    "```\n",
    "m_t = β₁ m_{t-1} + (1-β₁) ∇f(θ_t)           [First moment estimate]\n",
    "v_t = β₂ v_{t-1} + (1-β₂) (∇f(θ_t))²        [Second moment estimate]\n",
    "\n",
    "m̂_t = m_t / (1 - β₁ᵗ)                        [Bias correction for first moment]\n",
    "v̂_t = v_t / (1 - β₂ᵗ)                        [Bias correction for second moment]\n",
    "\n",
    "θ_{t+1} = θ_t - η m̂_t / (√v̂_t + ε)\n",
    "```\n",
    "\n",
    "Where:\n",
    "- $\\beta_1$: exponential decay rate for first moment (typically 0.9)\n",
    "- $\\beta_2$: exponential decay rate for second moment (typically 0.999)\n",
    "- $m_t$: biased first moment estimate (mean of gradients)\n",
    "- $v_t$: biased second moment estimate (uncentered variance of gradients)\n",
    "- $\\hat{m}_t$, $\\hat{v}_t$: bias-corrected estimates\n",
    "\n",
    "**Mathematical Intuition:**\n",
    "\n",
    "**First Moment ($m_t$):** Exponentially weighted moving average of gradients\n",
    "```\n",
    "m_t = (1-β₁) Σᵢ₌₁ᵗ β₁^(t-i) ∇f(θᵢ)\n",
    "```\n",
    "\n",
    "**Second Moment ($v_t$):** Exponentially weighted moving average of squared gradients\n",
    "```\n",
    "v_t = (1-β₂) Σᵢ₌₁ᵗ β₂^(t-i) (∇f(θᵢ))²\n",
    "```\n",
    "\n",
    "**Why Bias Correction?**\n",
    "\n",
    "When initialized at $m_0 = 0$, $v_0 = 0$:\n",
    "- Early estimates are biased toward zero\n",
    "- $E[m_t] \\neq E[\\nabla f(\\theta_t)]$ in early iterations\n",
    "- Bias correction factor $(1-\\beta^t)$ compensates for this initialization bias\n",
    "\n",
    "**Key Properties:**\n",
    "\n",
    "1. **Combines momentum + adaptive learning**: Gets benefits of both methods\n",
    "2. **Bias correction**: Ensures accurate estimates especially early in training\n",
    "3. **Invariance to gradient rescaling**: Update magnitude is invariant to gradient scale\n",
    "4. **Bounded step sizes**: Step size has bounds related to learning rate\n",
    "\n",
    "**Convergence Guarantees:**\n",
    "\n",
    "For convex functions, Adam achieves regret bound:\n",
    "```\n",
    "R(T) ≤ O(√T)\n",
    "```\n",
    "\n",
    "This means average regret goes to zero at rate $O(1/\\sqrt{T})$.\n",
    "\n",
    "**Why it works:**\n",
    "- First moment (momentum) provides direction information and noise reduction\n",
    "- Second moment (adaptive learning) provides scaling information\n",
    "- Bias correction prevents overly large steps early on\n",
    "- Combination is robust to hyperparameter choices\n",
    "\n",
    "**Comparison of effective step sizes:**\n",
    "\n",
    "| Optimizer | Effective Step Size |\n",
    "|-----------|-------------------|\n",
    "| SGD | $\\eta$ |\n",
    "| Momentum | $\\eta$ (amplified by velocity) |\n",
    "| RMSprop | $\\eta / \\sqrt{E[g^2]}$ |\n",
    "| Adam | $\\eta \\cdot \\hat{m} / \\sqrt{\\hat{v}}$ |\n",
    "\n",
    "---\n",
    "\n",
    "Adam (Adaptive Moment Estimation) combines momentum and adaptive learning rates for robust optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bzmv4ccyb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adam_optimization(parametric_model, formula, parameters,\n",
    "                     learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8,\n",
    "                     max_iterations=100, convergence_threshold=1e-6,\n",
    "                     minimize=True, gradient_clip=None):\n",
    "    \"\"\"\n",
    "    Adam Optimizer - combines momentum and adaptive learning rates\n",
    "    \n",
    "    Args:\n",
    "        parametric_model: Storm parametric model\n",
    "        formula: Property formula to optimize\n",
    "        parameters: Model parameters to optimize\n",
    "        learning_rate: Learning rate (typically 0.001)\n",
    "        beta1: Exponential decay rate for first moment (typically 0.9)\n",
    "        beta2: Exponential decay rate for second moment (typically 0.999)\n",
    "        epsilon: Small constant for numerical stability\n",
    "        max_iterations: Maximum optimization iterations\n",
    "        convergence_threshold: Stop if objective change < threshold\n",
    "        minimize: True to minimize, False to maximize objective\n",
    "        gradient_clip: Maximum gradient magnitude (None for no clipping)\n",
    "    \"\"\"\n",
    "    # Initialize parameters\n",
    "    current_values = {p: stormpy.RationalRF(0.5) for p in parameters}\n",
    "    instantiator = stormpy.pars.ModelInstantiator(parametric_model)\n",
    "    \n",
    "    # Initialize first moment (momentum) and second moment (adaptive lr) estimates\n",
    "    m = {p: 0.0 for p in parameters}  # First moment\n",
    "    v = {p: 0.0 for p in parameters}  # Second moment\n",
    "    \n",
    "    prev_objective = None\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        # Instantiate model with current parameters\n",
    "        concrete_model = instantiator.instantiate(current_values)\n",
    "        \n",
    "        # Model check to get objective value\n",
    "        result = stormpy.model_checking(concrete_model, formula)\n",
    "        objective = float(result.at(concrete_model.initial_states[0]))\n",
    "        \n",
    "        # Check convergence\n",
    "        if prev_objective is not None and abs(objective - prev_objective) < convergence_threshold:\n",
    "            print(f\"Converged at iteration {iteration}\")\n",
    "            break\n",
    "        \n",
    "        # Compute gradients\n",
    "        gradients = compute_gradients(parametric_model, parameters)\n",
    "        \n",
    "        # Update parameters using Adam\n",
    "        for param in parameters:\n",
    "            grad_value = evaluate_gradient_improved(gradients[param], current_values)\n",
    "            \n",
    "            # Apply gradient direction based on minimize/maximize\n",
    "            grad_direction = grad_value if minimize else -grad_value\n",
    "            \n",
    "            # Gradient clipping (optional)\n",
    "            if gradient_clip is not None:\n",
    "                grad_direction = np.clip(grad_direction, -gradient_clip, gradient_clip)\n",
    "            \n",
    "            # Update biased first moment estimate\n",
    "            m[param] = beta1 * m[param] + (1 - beta1) * grad_direction\n",
    "            \n",
    "            # Update biased second raw moment estimate\n",
    "            v[param] = beta2 * v[param] + (1 - beta2) * grad_direction**2\n",
    "            \n",
    "            # Compute bias-corrected first moment estimate\n",
    "            m_hat = m[param] / (1 - beta1**(iteration + 1))\n",
    "            \n",
    "            # Compute bias-corrected second raw moment estimate\n",
    "            v_hat = v[param] / (1 - beta2**(iteration + 1))\n",
    "            \n",
    "            # Update parameter value\n",
    "            new_value = float(current_values[param]) - learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n",
    "            current_values[param] = stormpy.RationalRF(clip_probability(new_value))\n",
    "        \n",
    "        if iteration % 10 == 0:\n",
    "            print(f\"Iteration {iteration}: Objective = {objective:.6f}\")\n",
    "        \n",
    "        prev_objective = objective\n",
    "    \n",
    "    print(f\"Final Objective: {objective:.6f}\")\n",
    "    return current_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ek5v496rpq",
   "metadata": {},
   "source": [
    "### Usage Examples\n",
    "\n",
    "Test the different optimizers on your parametric model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mk2fqxadskq",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Gradient Descent with Momentum\n",
    "print(\"=\" * 60)\n",
    "print(\"Testing Gradient Descent with Momentum\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "optimal_params_momentum = gradient_descent_momentum(\n",
    "    parametric_model, \n",
    "    exec.property[0].raw_formula, \n",
    "    parameters,\n",
    "    learning_rate=0.01,\n",
    "    momentum=0.9,\n",
    "    max_iterations=100,\n",
    "    minimize=True  # Set to False if maximizing the objective\n",
    ")\n",
    "\n",
    "# Evaluate final result\n",
    "instantiator = stormpy.pars.ModelInstantiator(parametric_model)\n",
    "final_model_momentum = instantiator.instantiate(optimal_params_momentum)\n",
    "result_momentum = stormpy.model_checking(final_model_momentum, exec.property[0].raw_formula)\n",
    "print(f\"\\nFinal result with Momentum: {result_momentum.at(final_model_momentum.initial_states[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nml14y96qx",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: RMSprop Optimizer\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Testing RMSprop Optimizer\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "optimal_params_rmsprop = rmsprop_optimization(\n",
    "    parametric_model, \n",
    "    exec.property[0].raw_formula, \n",
    "    parameters,\n",
    "    learning_rate=0.01,\n",
    "    decay_rate=0.9,\n",
    "    max_iterations=100,\n",
    "    minimize=True\n",
    ")\n",
    "\n",
    "# Evaluate final result\n",
    "final_model_rmsprop = instantiator.instantiate(optimal_params_rmsprop)\n",
    "result_rmsprop = stormpy.model_checking(final_model_rmsprop, exec.property[0].raw_formula)\n",
    "print(f\"\\nFinal result with RMSprop: {result_rmsprop.at(final_model_rmsprop.initial_states[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uao2kw0y6nf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: Adam Optimizer (Recommended)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Testing Adam Optimizer\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "optimal_params_adam = adam_optimization(\n",
    "    parametric_model, \n",
    "    exec.property[0].raw_formula, \n",
    "    parameters,\n",
    "    learning_rate=0.01,\n",
    "    beta1=0.9,\n",
    "    beta2=0.999,\n",
    "    max_iterations=100,\n",
    "    minimize=True,\n",
    "    gradient_clip=10.0  # Clip gradients to prevent instability\n",
    ")\n",
    "\n",
    "# Evaluate final result\n",
    "final_model_adam = instantiator.instantiate(optimal_params_adam)\n",
    "result_adam = stormpy.model_checking(final_model_adam, exec.property[0].raw_formula)\n",
    "print(f\"\\nFinal result with Adam: {result_adam.at(final_model_adam.initial_states[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8iqpmkyp97w",
   "metadata": {},
   "source": [
    "### Comparison and Analysis\n",
    "\n",
    "Compare the performance of different optimizers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036iegend8hf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare optimizer results\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"OPTIMIZER COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "results_comparison = {\n",
    "    \"Momentum\": float(result_momentum.at(final_model_momentum.initial_states[0])),\n",
    "    \"RMSprop\": float(result_rmsprop.at(final_model_rmsprop.initial_states[0])),\n",
    "    \"Adam\": float(result_adam.at(final_model_adam.initial_states[0]))\n",
    "}\n",
    "\n",
    "for optimizer_name, objective_value in results_comparison.items():\n",
    "    print(f\"{optimizer_name:15s}: {objective_value:.6f}\")\n",
    "\n",
    "best_optimizer = min(results_comparison, key=results_comparison.get)\n",
    "print(f\"\\nBest optimizer: {best_optimizer} with objective = {results_comparison[best_optimizer]:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qc96jzbhjjq",
   "metadata": {},
   "source": [
    "### Additional Features:\n",
    "- **Gradient clipping**: Prevents exploding gradients\n",
    "- **Convergence detection**: Stops when objective change is below threshold\n",
    "- **Probability bounds**: Ensures parameters stay in valid $[0,1]$ range\n",
    "- **Improved gradient evaluation**: Properly handles multiple derivatives per parameter\n",
    "\n",
    "### Conclusion\n",
    "At each step the derivatives extracted from stormpy are zero for most parameters, hence they seem to not affect the reward objective, which is in fact unrealistic. The problem might be too complex for symbolic derivatives and potentially not be captured by gradient-based methods. Alternatives: random search or evolutionary algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ibg9gn18v9e",
   "metadata": {},
   "source": [
    "### Comparative Analysis\n",
    "\n",
    "**Convergence Behavior:**\n",
    "\n",
    "```\n",
    "Standard GD:    ━━━━━━━━━━→ (straight path, may oscillate)\n",
    "Momentum:       ━━━━━╱━━→   (builds speed, overshoots less)\n",
    "RMSprop:        ━┓━┓━→      (adaptive steps)\n",
    "Adam:           ━━━━━━→     (smooth, fast, adaptive)\n",
    "```\n",
    "\n",
    "**When to Use Each:**\n",
    "\n",
    "- **Standard GD**: Convex problems with well-conditioned Hessian, theoretical analysis\n",
    "- **Momentum**: Problems with ravines, want faster convergence, can tolerate some overshoot\n",
    "- **RMSprop**: Non-stationary objectives, different parameter scales, recurrent neural networks\n",
    "- **Adam**: Default choice for most problems, especially when gradient is sparse or noisy\n",
    "\n",
    "**Hyperparameter Sensitivity:**\n",
    "\n",
    "- **Standard GD**: Very sensitive to learning rate $\\eta$\n",
    "- **Momentum**: Moderately sensitive to $\\eta$ and $\\beta$\n",
    "- **RMSprop**: Less sensitive, but $\\rho$ affects adaptation speed\n",
    "- **Adam**: Least sensitive, default values ($\\beta_1=0.9$, $\\beta_2=0.999$) work well across many problems\n",
    "\n",
    "---\n",
    "\n",
    "### Memory-less POMDP Controller Problem\n",
    "\n",
    "**Why these matter for parametric Markov chains:**\n",
    "\n",
    "1. **Different parameter influence**: Some FSC parameters may have much larger impact on objective than others → RMSprop/Adam handle this automatically\n",
    "\n",
    "2. **Sparse gradients**: Most parameters show zero derivatives in the output logs → Adam's momentum can help explore despite sparse gradients\n",
    "\n",
    "3. **Parameter correlations**: POMDP controller parameters may have complex interdependencies → Momentum helps navigate correlated parameter space\n",
    "\n",
    "4. **Probability constraints**: Parameters must stay in $[0,1]$ → Adaptive learning rates prevent overshooting bounds\n",
    "\n",
    "**Theoretical limitation in this case:**\n",
    "\n",
    "If `stormpy.pars.gather_derivatives` returns mostly empty sets (zero symbolic derivatives), it suggests:\n",
    "- Parameters may not appear in reachability probabilities (derivative truly is zero)\n",
    "- Symbolic differentiation may not capture all dependencies\n",
    "- Need to verify that FSC parameters actually influence the verification property\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fgjikhqd8c",
   "metadata": {},
   "source": [
    "### 10. Practical Hyperparameter Guidance\n",
    "\n",
    "**Default Starting Points:**\n",
    "\n",
    "| Method | Learning Rate | Other Parameters | When to Use |\n",
    "|--------|---------------|------------------|-------------|\n",
    "| SGD | 0.1 - 0.01 | - | Simple convex problems |\n",
    "| Momentum | 0.01 - 0.001 | β = 0.9 | Ill-conditioned problems |\n",
    "| RMSprop | 0.001 - 0.0001 | ρ = 0.9 | RNNs, non-stationary |\n",
    "| Adam | 0.001 - 0.0001 | β₁=0.9, β₂=0.999 | Default choice |\n",
    "\n",
    "**Hyperparameter Tuning Strategy:**\n",
    "\n",
    "1. Start with defaults (especially for Adam)\n",
    "2. If diverging: decrease learning rate by 10× \n",
    "3. If too slow: increase learning rate by 3×\n",
    "4. For momentum methods: increase β for smoother updates\n",
    "5. For Adam: rarely need to change β₁, β₂\n",
    "\n",
    "**Common Failure Modes:**\n",
    "\n",
    "- **Oscillation**: Learning rate too high → decrease η\n",
    "- **Slow progress**: Learning rate too low or trapped in plateau → increase η or add noise\n",
    "- **Early stopping**: Momentum overshoots → decrease β or η\n",
    "- **Exploding values**: Gradient explosion → add gradient clipping or decrease η"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xytys98ua8",
   "metadata": {},
   "source": [
    "### 11. Key Research Papers and References\n",
    "\n",
    "**Foundational Papers:**\n",
    "\n",
    "1. **Momentum:**\n",
    "   - Polyak, B. T. (1964). \"Some methods of speeding up the convergence of iteration methods\"\n",
    "   - Nesterov, Y. (1983). \"A method for solving the convex programming problem with convergence rate O(1/k²)\"\n",
    "\n",
    "2. **RMSprop:**\n",
    "   - Hinton, G., Srivastava, N., & Swersky, K. (2012). \"Neural Networks for Machine Learning\" - Lecture 6a\n",
    "   - Tieleman, T., & Hinton, G. (2012). \"Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude\"\n",
    "\n",
    "3. **Adam:**\n",
    "   - Kingma, D. P., & Ba, J. (2014). \"Adam: A Method for Stochastic Optimization\" - ICLR 2015\n",
    "   - [arXiv:1412.6980](https://arxiv.org/abs/1412.6980)\n",
    "\n",
    "**Survey Papers:**\n",
    "\n",
    "- Ruder, S. (2016). \"An overview of gradient descent optimization algorithms\" - [arXiv:1609.04747](https://arxiv.org/abs/1609.04747)\n",
    "- Bottou, L., Curtis, F. E., & Nocedal, J. (2018). \"Optimization Methods for Large-Scale Machine Learning\" - SIAM Review\n",
    "\n",
    "**For POMDP Controllers:**\n",
    "\n",
    "- Junges, S., et al. (2018). \"Finite-State Controllers of POMDPs using Parameter Synthesis\" - UAI 2018\n",
    "- Carr, S., et al. (2019). \"Counterexample-Guided Strategy Improvement for POMDPs Using Recurrent Neural Networks\" - IJCAI 2019\n",
    "\n",
    "---\n",
    "\n",
    "### Gradient-Based Methods May Not Be Sufficient\n",
    "\n",
    "**Current Challenge:**\n",
    "\n",
    "From the notebook output, most parameters have `set()` (empty) derivatives, with only `p1_0` and `p1_1` showing non-zero symbolic derivatives. This indicates:\n",
    "\n",
    "**Why gradient descent may struggle:**\n",
    "\n",
    "1. **Structural zeros**: Parameters that don't appear in transition probabilities have genuinely zero derivatives\n",
    "2. **Discrete structure**: POMDP finite-state controllers may have discontinuous objective landscapes\n",
    "3. **Symbolic limitations**: `stormpy.pars.gather_derivatives` may only compute derivatives for parameters that appear explicitly in transition functions\n",
    "\n",
    "If sensitivity is near zero for all parameters, the FSC parameterization may not be suitable for this POMDP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sl50h1vq5x",
   "metadata": {},
   "source": [
    "### Diagnostic: Test Parameter Sensitivity\n",
    "\n",
    "Before investing in optimization, verify that parameters actually influence the objective:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dpw5n2a2kge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter Sensitivity Analysis\n",
      "================================================================================\n",
      "\n",
      "Parameter: p14_0\n",
      "  Values tested: [0.1, 0.3, 0.5, 0.7, 0.9]\n",
      "  Objectives:    ['623.4444', '625.9048', '630.3333', '640.6667', '692.3333']\n",
      "  Sensitivity:   68.888889 ✓ SENSITIVE\n",
      "\n",
      "Parameter: p23_0\n",
      "  Values tested: [0.1, 0.3, 0.5, 0.7, 0.9]\n",
      "  Objectives:    ['469.4889', '526.9333', '630.3333', '871.6000', '2077.9333']\n",
      "  Sensitivity:   1608.444444 ✓ SENSITIVE\n",
      "\n",
      "Parameter: p16_0\n",
      "  Values tested: [0.1, 0.3, 0.5, 0.7, 0.9]\n",
      "  Objectives:    ['580.5111', '598.3048', '630.3333', '705.0667', '1078.7333']\n",
      "  Sensitivity:   498.222222 ✓ SENSITIVE\n",
      "\n",
      "Parameter: p10_0\n",
      "  Values tested: [0.1, 0.3, 0.5, 0.7, 0.9]\n",
      "  Objectives:    ['471.8889', '528.4762', '630.3333', '868.0000', '2056.3333']\n",
      "  Sensitivity:   1584.444444 ✓ SENSITIVE\n",
      "\n",
      "Parameter: p8_0\n",
      "  Values tested: [0.1, 0.3, 0.5, 0.7, 0.9]\n",
      "  Objectives:    ['494.3778', '542.9333', '630.3333', '834.2667', '1853.9333']\n",
      "  Sensitivity:   1359.555556 ✓ SENSITIVE\n",
      "\n",
      "Parameter: p6_0\n",
      "  Values tested: [0.1, 0.3, 0.5, 0.7, 0.9]\n",
      "  Objectives:    ['468.5556', '526.3333', '630.3333', '873.0000', '2086.3333']\n",
      "  Sensitivity:   1617.777778 ✓ SENSITIVE\n",
      "\n",
      "Parameter: p20_0\n",
      "  Values tested: [0.1, 0.3, 0.5, 0.7, 0.9]\n",
      "  Objectives:    ['582.7333', '599.7333', '630.3333', '701.7333', '1058.7333']\n",
      "  Sensitivity:   476.000000 ✓ SENSITIVE\n",
      "\n",
      "Parameter: p0_0\n",
      "  Values tested: [0.1, 0.3, 0.5, 0.7, 0.9]\n",
      "  Objectives:    ['315.1667', '233477926873.3628', '630.3333', '334.4870', '324.8512']\n",
      "  Sensitivity:   233477926558.196136 ✓ SENSITIVE\n",
      "\n",
      "Parameter: p11_0\n",
      "  Values tested: [0.1, 0.3, 0.5, 0.7, 0.9]\n",
      "  Objectives:    ['475.4444', '530.7619', '630.3333', '862.6667', '2024.3333']\n",
      "  Sensitivity:   1548.888889 ✓ SENSITIVE\n",
      "\n",
      "Parameter: p1_1\n",
      "  Values tested: [0.1, 0.3, 0.5, 0.7, 0.9]\n",
      "  Objectives:    ['630.3333', '630.3333', '630.3333', '630.3333', '630.3333']\n",
      "  Sensitivity:   0.000000 ✗ NOT SENSITIVE\n",
      "\n",
      "================================================================================\n",
      "Summary:\n",
      "Sensitive parameters: 9/10\n",
      "Max sensitivity: 233477926558.196136\n",
      "Mean sensitivity: 23347793532.041836\n",
      "WARN  (GmmxxLinearEquationSolver.cpp:133): Iterative solver did not converge within 11 iteration(s).\n",
      "WARN  (GmmxxLinearEquationSolver.cpp:133): Iterative solver did not converge within 11 iteration(s).\n"
     ]
    }
   ],
   "source": [
    "# Test parameter sensitivity - does changing parameters affect the objective?\n",
    "import random\n",
    "\n",
    "print(\"Parameter Sensitivity Analysis\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Test a random sample of parameters\n",
    "params_to_test = random.sample(list(parameters), min(10, len(parameters)))\n",
    "test_values = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "\n",
    "sensitivity_results = {}\n",
    "instantiator = stormpy.pars.ModelInstantiator(parametric_model)\n",
    "\n",
    "for param_to_test in params_to_test:\n",
    "    objectives = []\n",
    "    \n",
    "    for val in test_values:\n",
    "        test_params = {p: stormpy.RationalRF(0.5) for p in parameters}\n",
    "        test_params[param_to_test] = stormpy.RationalRF(val)\n",
    "        test_model = instantiator.instantiate(test_params)\n",
    "        result = stormpy.model_checking(test_model, exec.property[0].raw_formula)\n",
    "        objectives.append(float(result.at(test_model.initial_states[0])))\n",
    "    \n",
    "    sensitivity = max(objectives) - min(objectives)\n",
    "    sensitivity_results[str(param_to_test)] = sensitivity\n",
    "    \n",
    "    print(f\"\\nParameter: {param_to_test}\")\n",
    "    print(f\"  Values tested: {test_values}\")\n",
    "    print(f\"  Objectives:    {[f'{obj:.4f}' for obj in objectives]}\")\n",
    "    print(f\"  Sensitivity:   {sensitivity:.6f} {'✓ SENSITIVE' if sensitivity > 1e-6 else '✗ NOT SENSITIVE'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Summary:\")\n",
    "sensitive_params = sum(1 for s in sensitivity_results.values() if s > 1e-6)\n",
    "print(f\"Sensitive parameters: {sensitive_params}/{len(params_to_test)}\")\n",
    "print(f\"Max sensitivity: {max(sensitivity_results.values()):.6f}\")\n",
    "print(f\"Mean sensitivity: {sum(sensitivity_results.values())/len(sensitivity_results):.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uv(OOP)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
